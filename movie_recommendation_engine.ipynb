{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, LongType, StringType\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import split, explode\n",
    "from pyspark.sql.functions import col, size, split, udf\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating spark session/\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Movie Recommendation\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Datasets\n",
    "movies_df = spark.read.load(r'C:\\My Drive\\UMBC\\Code\\BigDataProject\\Project_Dataset\\movies.csv', format = 'csv', header = True)\n",
    "ratings_df = spark.read.load(r'C:\\My Drive\\UMBC\\Code\\BigDataProject\\Project_Dataset\\ratings.csv', format = 'csv', header = True)\n",
    "tags_df = spark.read.load(r'C:\\My Drive\\UMBC\\Code\\BigDataProject\\Project_Dataset\\tags.csv', format = 'csv', header = True)\n",
    "links_df = spark.read.load(r'C:\\My Drive\\UMBC\\Code\\BigDataProject\\Project_Dataset\\links.csv', format = 'csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------- \tMovies Schema\t --------------------\n",
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "-------------------- \tRatings Schema\t --------------------\n",
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n",
      "-------------------- \tTags Schema\t --------------------\n",
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n",
      "-------------------- \tLinks Schema\t --------------------\n",
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- imdbId: string (nullable = true)\n",
      " |-- tmdbId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looking at the schema of above dataframes\n",
    "print(\"\\n\")\n",
    "print(\"--\" * 10, \"\\tMovies Schema\\t\", \"--\" * 10,)\n",
    "movies_df.printSchema()\n",
    "\n",
    "print(\"--\" * 10, \"\\tRatings Schema\\t\", \"--\" * 10,)\n",
    "ratings_df.printSchema()\n",
    "\n",
    "print(\"--\" * 10, \"\\tTags Schema\\t\", \"--\" * 10,)\n",
    "tags_df.printSchema()\n",
    "\n",
    "print(\"--\" * 10, \"\\tLinks Schema\\t\", \"--\" * 10)\n",
    "links_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------- \tNew Movies Schema\t --------------------\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      "\n",
      "-------------------- \tNew Ratings Schema\t --------------------\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "-------------------- \tNew Tags Schema\t --------------------\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "-------------------- \tNew Links Schema\t --------------------\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- imdbId: integer (nullable = true)\n",
      " |-- tmdbId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For now, I'm gonna concentrate only on movies and ratings dataset.\n",
    "# rating's field values such as userId and movieId and rating is of STRING datatype which I'll convert into int\n",
    "\n",
    "ratings_df = ratings_df.select(ratings_df[\"userId\"].cast(\"int\"),\n",
    "                               ratings_df[\"movieId\"].cast(\"int\"),\n",
    "                               ratings_df[\"rating\"].cast(\"float\"),\n",
    "                               ratings_df[\"timestamp\"].cast(\"int\"))\n",
    "\n",
    "# Similar for the tags dataset\n",
    "tags_df = tags_df.select(tags_df[\"userId\"].cast(\"int\"),\n",
    "                         tags_df[\"movieId\"].cast(\"int\"),\n",
    "                         tags_df[\"timestamp\"].cast(\"int\"))\n",
    "\n",
    "# Similar for links dataset\n",
    "links_df = links_df.select(links_df[\"movieId\"].cast(\"int\"),\n",
    "                           links_df[\"imdbId\"].cast(\"int\"),\n",
    "                           links_df[\"tmdbId\"].cast(\"int\"))\n",
    "\n",
    "# Printing out the new Schema\n",
    "print(\"\\n\")\n",
    "print(\"--\" * 10, \"\\tNew Movies Schema\\t\", \"--\" * 10,)\n",
    "movies_df.printSchema()\n",
    "\n",
    "print(\"--\" * 10, \"\\tNew Ratings Schema\\t\", \"--\" * 10,)\n",
    "ratings_df.printSchema()\n",
    "\n",
    "print(\"--\" * 10, \"\\tNew Tags Schema\\t\", \"--\" * 10,)\n",
    "tags_df.printSchema()\n",
    "\n",
    "print(\"--\" * 10, \"\\tNew Links Schema\\t\", \"--\" * 10)\n",
    "links_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------- \tMissing Values in movies\t --------------------\n",
      "+-------+-----+------+\n",
      "|movieId|title|genres|\n",
      "+-------+-----+------+\n",
      "|      0|    0|     0|\n",
      "+-------+-----+------+\n",
      "\n",
      "\n",
      "\n",
      "-------------------- \tMissing Values in Ratings\t --------------------\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     0|      0|     0|        0|\n",
      "+------+-------+------+---------+\n",
      "\n",
      "\n",
      "\n",
      "-------------------- \tMissing Values in tags\t --------------------\n",
      "+------+-------+---------+\n",
      "|userId|movieId|timestamp|\n",
      "+------+-------+---------+\n",
      "|     0|      0|        0|\n",
      "+------+-------+---------+\n",
      "\n",
      "\n",
      "\n",
      "-------------------- \tMissing Values in Links\t --------------------\n",
      "+-------+------+------+\n",
      "|movieId|imdbId|tmdbId|\n",
      "+-------+------+------+\n",
      "|      0|     0|     0|\n",
      "+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking if any values are missing:\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"--\" * 10, \"\\tMissing Values in movies\\t\", \"--\" * 10,)\n",
    "movies_df.select([count(when(isnan(c), c)).alias(c) for c in movies_df.columns]).show()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"--\" * 10, \"\\tMissing Values in Ratings\\t\", \"--\" * 10,)\n",
    "ratings_df.select([count(when(isnan(c), c)).alias(c) for c in ratings_df.columns]).show()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"--\" * 10, \"\\tMissing Values in tags\\t\", \"--\" * 10,)\n",
    "tags_df.select([count(when(isnan(c), c)).alias(c) for c in tags_df.columns]).show()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"--\" * 10, \"\\tMissing Values in Links\\t\", \"--\" * 10,)\n",
    "links_df.select([count(when(isnan(c), c)).alias(c) for c in links_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users who rated movies:  610\n",
      "Number of movies in the dataset:  9742\n"
     ]
    }
   ],
   "source": [
    "# Our dataset have no missing values... Great!\n",
    "# Let's do some exploratory analysis to ge better insights of our dataset\n",
    "\n",
    "#print(ratings_df.count(), len(ratings_df.columns))\n",
    "print(\"Number of users who rated movies: \", ratings_df.select('userId').distinct().count())\n",
    "print(\"Number of movies in the dataset: \", movies_df.select('movieId').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|movies|\n",
      "+------+\n",
      "|9724  |\n",
      "+------+\n",
      "\n",
      "+--------------------------------------------+\n",
      "|unrated_movie_title                         |\n",
      "+--------------------------------------------+\n",
      "|Innocents, The (1961)                       |\n",
      "|Niagara (1953)                              |\n",
      "|For All Mankind (1989)                      |\n",
      "|Color of Paradise, The (Rang-e khoda) (1999)|\n",
      "|I Know Where I'm Going! (1945)              |\n",
      "|Chosen, The (1981)                          |\n",
      "|Road Home, The (Wo de fu qin mu qin) (1999) |\n",
      "|Scrooge (1970)                              |\n",
      "|Proof (1991)                                |\n",
      "|Parallax View, The (1974)                   |\n",
      "|This Gun for Hire (1942)                    |\n",
      "|Roaring Twenties, The (1939)                |\n",
      "|Mutiny on the Bounty (1962)                 |\n",
      "|In the Realms of the Unreal (2004)          |\n",
      "|Twentieth Century (1934)                    |\n",
      "|Call Northside 777 (1948)                   |\n",
      "|Browning Version, The (1951)                |\n",
      "|Chalet Girl (2011)                          |\n",
      "+--------------------------------------------+\n",
      "\n",
      "Number of movies which is rated only one time:  3459\n"
     ]
    }
   ],
   "source": [
    "# creating interface for spark SQL\n",
    "\n",
    "movies_df.createOrReplaceTempView(\"Movies\")\n",
    "ratings_df.createOrReplaceTempView(\"Ratings\")\n",
    "\n",
    "numberOfMoviesRated = spark.sql(\"SELECT COUNT(DISTINCT(Movies.movieId)) AS movies \\\n",
    "                                 FROM Movies \\\n",
    "                                 LEFT JOIN Ratings \\\n",
    "                                 ON Movies.movieId = Ratings.movieId \\\n",
    "                                 WHERE Ratings.rating IS NOT NULL\")\n",
    "numberOfMoviesRated.show(truncate = False)\n",
    "\n",
    "unrated_movies_count = spark.sql(\"SELECT COUNT(DISTINCT(Movies.movieId)) AS unrated_count \\\n",
    "                                                       FROM MOVIES \\\n",
    "                                                       LEFT JOIN Ratings \\\n",
    "                                                       ON Movies.movieId = Ratings.movieId \\\n",
    "                                                       WHERE Ratings.rating IS NULL\")\n",
    "\n",
    "unrated_movies_title = spark.sql(\"SELECT Movies.title AS unrated_movie_title \\\n",
    "                                                       FROM MOVIES \\\n",
    "                                                       LEFT JOIN Ratings \\\n",
    "                                                       ON Movies.movieId = Ratings.movieId \\\n",
    "                                                       WHERE Ratings.rating IS NULL\")\n",
    "unrated_movies_title.show(truncate = False)\n",
    "\n",
    "rating_details = spark.sql(\"SELECT Movies.title, COUNT(Ratings.rating) AS numberOfRating \\\n",
    "                            FROM Movies \\\n",
    "                            LEFT JOIN Ratings \\\n",
    "                            ON Movies.movieId = Ratings.movieId \\\n",
    "                            GROUP BY Movies.title \\\n",
    "                            ORDER BY numberOfRating\")\n",
    "rating_details.toPandas()\n",
    "print(\"Number of movies which is rated only one time: \", rating_details[rating_details[\"numberOfRating\"] < 2].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 4.0), (1, 3, 4.0), (1, 6, 4.0)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "rating_df_new = sc.textFile(r'C:\\My Drive\\UMBC\\Code\\BigDataProject\\Project_Dataset\\ratings.csv')\n",
    "header = rating_df_new.take(1)[0]\n",
    "rating_data = rating_df_new.filter(lambda line: line!=header).\\\n",
    "              map(lambda line: line.split(\",\")).\\\n",
    "              map(lambda tokens: (int(tokens[0]), int(tokens[1]), float(tokens[2]))).cache()\n",
    "rating_data.take(3)\n",
    "\n",
    "# print(\"-\" * 60)\n",
    "# print('There are {} instances of rating'.format(rating_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'Toy Story (1995)'),\n",
       " ('2', 'Jumanji (1995)'),\n",
       " ('3', 'Grumpier Old Men (1995)')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df_new = sc.textFile(r'C:\\My Drive\\UMBC\\Code\\BigDataProject\\Project_Dataset\\movies.csv')\n",
    "header = movie_df_new.take(1)[0]\n",
    "\n",
    "movie_data = movie_df_new.filter(lambda line: line!=header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n",
    "    \n",
    "movie_data.take(3)\n",
    "\n",
    "# print(\"-\" * 60)\n",
    "# print('There are {} instances of Movies'.format(movie_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_RDD, valid_RDD, test_RDD = rating_data.randomSplit([0.6, 0.2, 0.2], seed = 42)\n",
    "valid_RDD_forPrediction = valid_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_RDD_forPrediction = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.9058043327998001\n",
      "Current value of min_error 0.9058043327998001\n",
      "For rank 8 the RMSE is 0.9156655436588836\n",
      "For rank 12 the RMSE is 0.9078411395548683\n",
      "--------------------------------------------------\n",
      "The best model was trained with rank 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 42\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "optimal_rank = -1\n",
    "optimal_iteration = -1\n",
    "\n",
    "for rank in ranks:\n",
    "    model = ALS.train(train_RDD, rank, seed = seed, iterations = iterations,\n",
    "                      lambda_ = regularization_parameter)\n",
    "    predictions = model.predictAll(valid_RDD_forPrediction).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = valid_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print('For rank {} the RMSE is {}'.format(rank, error))\n",
    "    \n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        print('Current value of min_error', min_error)\n",
    "        best_rank = rank\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print('The best model was trained with rank {}'.format(best_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((368, 3272), 2.2103941239381957),\n",
       " ((603, 3272), 2.7094106274500698),\n",
       " ((414, 3272), 3.3172783499986758)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 367), (4.0, 3.8778425793950486)),\n",
       " ((1, 553), (5.0, 4.48872221960911)),\n",
       " ((1, 673), (3.0, 2.9687504298721707))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.9048780956510838\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(train_RDD, best_rank, seed = seed, iterations = iterations,\n",
    "                      lambda_ = regularization_parameter)\n",
    "predictions = model.predictAll(test_RDD_forPrediction).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print('For testing data the RMSE is {}'.format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 260, 4), (0, 1, 3), (0, 16, 3), (0, 25, 4), (0, 32, 4), (0, 335, 1), (0, 379, 1), (0, 296, 3), (0, 858, 5), (0, 50, 4)]\n"
     ]
    }
   ],
   "source": [
    "new_user_ID = 0\n",
    "\n",
    "# (userID, movieID, rating)\n",
    "new_user_ratings = [\n",
    "     (0,260,4), # Star Wars (1977)\n",
    "     (0,1,3), # Toy Story (1995)\n",
    "     (0,16,3), # Casino (1995)\n",
    "     (0,25,4), # Leaving Las Vegas (1995)\n",
    "     (0,32,4), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
    "     (0,335,1), # Flintstones, The (1994)\n",
    "     (0,379,1), # Timecop (1994)\n",
    "     (0,296,3), # Pulp Fiction (1994)\n",
    "     (0,858,5) , # Godfather, The (1972)\n",
    "     (0,50,4) # Usual Suspects, The (1995)\n",
    "    ]\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print(\"New user ratings: %s\" % new_user_ratings_RDD.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rating_data_RDD = rating_data.union(new_user_ratings_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training time:  19.06317687034607\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "new_model = ALS.train(new_rating_data_RDD, best_rank, seed = seed, iterations = iterations, lambda_ = regularization_parameter)\n",
    "stop_time = time()\n",
    "\n",
    "print(\"Model training time: \", stop_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_movie_ids = map(lambda x: x[1], new_user_ratings)\n",
    "unrated_movies_rdd = (movie_data.filter(lambda x: x[0] not in rated_movie_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "new_user_recommendations = new_model.predictAll(unrated_movies_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countAndAvg(idRatingTuple):\n",
    "    nratings = len(idRatingTuple[1])\n",
    "    return idRatingTuple[0], (nratings, float(sum(x for x in idRatingTuple[1])) / nratings)\n",
    "\n",
    "movie_titles = movie_data.map(lambda x: (int(x[0]), x[1]))\n",
    "movie_ID_ratings_RDD = (rating_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_ratings_RDD_avg = movie_ID_ratings_RDD.map(countAndAvg)\n",
    "movie_rating_counts_RDD = movie_ID_ratings_RDD_avg.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(69720, ((1.5170735890918814, 'Hood of Horror (2006)'), 1)),\n",
       " (3240, ((2.30472879362691, '\"Big Tease'), 2)),\n",
       " (98160, ((1.304571892555307, 'Nature Calls (2012)'), 1))]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation_RDD = new_user_recommendations.map(lambda x: (x.product, x.rating))\n",
    "recommendation_RDD_titleAndCount = recommendation_RDD.join(movie_titles).join(movie_rating_counts_RDD)\n",
    "recommendation_RDD_titleAndCount.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_RDD_titleAndCount = recommendation_RDD_titleAndCount.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hood of Horror (2006)', 1.5170735890918814, 1),\n",
       " ('\"Big Tease', 2.30472879362691, 2),\n",
       " ('Nature Calls (2012)', 1.304571892555307, 1)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation_RDD_titleAndCount.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies_to_recommend = recommendation_RDD_titleAndCount.filter(lambda r: r[2] > 25).takeOrdered(25, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Recommended movies: \n",
      "('\"Producers', 4.1968157790109775, 33)\n",
      "('Chinatown (1974)', 4.195708392289013, 59)\n",
      "('Citizen Kane (1941)', 4.178241501170903, 69)\n",
      "('Brazil (1985)', 4.168895069399608, 59)\n",
      "('Raging Bull (1980)', 4.155766137731009, 40)\n",
      "('Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)', 4.135269753625976, 97)\n",
      "('Old Boy (2003)', 4.116536880319541, 39)\n",
      "('\"Godfather', 4.11623343163422, 192)\n",
      "('Apocalypse Now (1979)', 4.111207228001691, 107)\n",
      "('Seven Samurai (Shichinin no samurai) (1954)', 4.106498543422082, 48)\n",
      "('Annie Hall (1977)', 4.105297111700647, 58)\n",
      "('\"Boot', 4.0916875545231175, 40)\n",
      "('\"Godfather: Part II', 4.086838530578542, 129)\n",
      "('There Will Be Blood (2007)', 4.071615674061283, 28)\n",
      "('Pulp Fiction (1994)', 4.055605924818113, 307)\n",
      "('12 Angry Men (1957)', 4.041446411778798, 57)\n",
      "('Blue Velvet (1986)', 4.036994733901926, 46)\n",
      "('Birdman: Or (The Unexpected Virtue of Ignorance) (2014)', 4.030885044493526, 26)\n",
      "('Rear Window (1954)', 4.015692872421883, 84)\n",
      "('Do the Right Thing (1989)', 4.008406613913488, 27)\n",
      "('Fargo (1996)', 4.007343675430864, 181)\n",
      "('Taxi Driver (1976)', 3.9902896510072434, 104)\n",
      "('Election (1999)', 3.981996303785261, 56)\n",
      "(\"One Flew Over the Cuckoo's Nest (1975)\", 3.976970154536199, 133)\n",
      "('Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)', 3.973513823320442, 27)\n"
     ]
    }
   ],
   "source": [
    "print('Top Recommended movies: \\n%s' % '\\n'.join(map(str, top_movies_to_recommend)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
